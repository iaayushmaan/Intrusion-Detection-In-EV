{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBm7Mu2mqyL7PW2vug2j4z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset1 Classification**"
      ],
      "metadata": {
        "id": "p9m8SKVBUxGG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RxseXizEZhMW"
      },
      "outputs": [],
      "source": [
        "# importing pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.core.internals.blocks import F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WkMQ0raN4EHP"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HDM5Z_f94JQs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import neighbors, datasets\n",
        "#from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "import sklearn.metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "98Pgr_fA4OYt"
      },
      "outputs": [],
      "source": [
        "#AttackFree= [0:2369397]\n",
        "#DoS= [0:656578]\n",
        "#Fuzzy= )[0:591989]\n",
        "#Impersonation= [0:995471]\n",
        "\n",
        "AttackFree= pd.read_csv('/content/Attack_free new.csv')[0:236939]\n",
        "DoS= pd.read_csv('/content/DoS_Attack_new.csv')[0:65657]\n",
        "Fuzzy= pd.read_csv('/content/Fuzzy_Attack_New.csv')[0:59198]\n",
        "Impersonation= pd.read_csv('/content/Impersonation_Attack_New.csv')[0:99547]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztRRWB_94c4N"
      },
      "outputs": [],
      "source": [
        "#Class1: Attack-Free\n",
        "\n",
        "AttackFree.iloc[:, 1]= label_encoder.fit_transform(AttackFree.iloc[:, 1])\n",
        "AttackFree.iloc[:, 2]= label_encoder.fit_transform(AttackFree.iloc[:, 2])\n",
        "AttackFree.iloc[:, 3]= label_encoder.fit_transform(AttackFree.iloc[:, 3])\n",
        "AttackFree.iloc[:, 4]= label_encoder.fit_transform(AttackFree.iloc[:, 4])\n",
        "AttackFree.iloc[:, 5]= label_encoder.fit_transform(AttackFree.iloc[:, 5])\n",
        "AttackFree.iloc[:, 6]= label_encoder.fit_transform(AttackFree.iloc[:, 6])\n",
        "AttackFree.iloc[:, 7]= label_encoder.fit_transform(AttackFree.iloc[:, 7])\n",
        "AttackFree.iloc[:, 8]= label_encoder.fit_transform(AttackFree.iloc[:, 8])\n",
        "AttackFree.iloc[:, 9]= label_encoder.fit_transform(AttackFree.iloc[:, 9])\n",
        "AttackFree.iloc[:, 10]= label_encoder.fit_transform(AttackFree.iloc[:, 10])\n",
        "AttackFree.iloc[:, 11]= label_encoder.fit_transform(AttackFree.iloc[:, 11])\n",
        "AttackFree.iloc[:, 12]= label_encoder.fit_transform(AttackFree.iloc[:, 12])\n",
        "AttackFree.iloc[:, 13]= label_encoder.fit_transform(AttackFree.iloc[:, 13])\n",
        "AttackFree.iloc[:, 14]= label_encoder.fit_transform(AttackFree.iloc[:, 14])\n",
        "AttackFree.iloc[:, 15]= label_encoder.fit_transform(AttackFree.iloc[:, 15])\n",
        "#AttackFree.iloc[:, 16]= label_encoder.fit_transform(AttackFree.iloc[:, 16])\n",
        "\n",
        "#Class2: DoS\n",
        "\n",
        "DoS.iloc[:, 1]= label_encoder.fit_transform(DoS.iloc[:, 1])\n",
        "DoS.iloc[:, 2]= label_encoder.fit_transform(DoS.iloc[:, 2])\n",
        "DoS.iloc[:, 3]= label_encoder.fit_transform(DoS.iloc[:, 3])\n",
        "DoS.iloc[:, 4]= label_encoder.fit_transform(DoS.iloc[:, 4])\n",
        "DoS.iloc[:, 5]= label_encoder.fit_transform(DoS.iloc[:, 5])\n",
        "DoS.iloc[:, 6]= label_encoder.fit_transform(DoS.iloc[:, 6])\n",
        "DoS.iloc[:, 7]= label_encoder.fit_transform(DoS.iloc[:, 7])\n",
        "DoS.iloc[:, 8]= label_encoder.fit_transform(DoS.iloc[:, 8])\n",
        "DoS.iloc[:, 9]= label_encoder.fit_transform(DoS.iloc[:, 9])\n",
        "DoS.iloc[:, 10]= label_encoder.fit_transform(DoS.iloc[:, 10])\n",
        "DoS.iloc[:, 11]= label_encoder.fit_transform(DoS.iloc[:, 11])\n",
        "DoS.iloc[:, 12]= label_encoder.fit_transform(DoS.iloc[:, 12])\n",
        "DoS.iloc[:, 13]= label_encoder.fit_transform(DoS.iloc[:, 13])\n",
        "DoS.iloc[:, 14]= label_encoder.fit_transform(DoS.iloc[:, 14])\n",
        "DoS.iloc[:, 15]= label_encoder.fit_transform(DoS.iloc[:, 15])\n",
        "#DoS.iloc[:, 16]= label_encoder.fit_transform(DoS.iloc[:, 16])\n",
        "\n",
        "#Class3: Fuzzy\n",
        "\n",
        "Fuzzy.iloc[:, 1]= label_encoder.fit_transform(Fuzzy.iloc[:, 1])\n",
        "Fuzzy.iloc[:, 2]= label_encoder.fit_transform(Fuzzy.iloc[:, 2])\n",
        "Fuzzy.iloc[:, 3]= label_encoder.fit_transform(Fuzzy.iloc[:, 3])\n",
        "Fuzzy.iloc[:, 4]= label_encoder.fit_transform(Fuzzy.iloc[:, 4])\n",
        "Fuzzy.iloc[:, 5]= label_encoder.fit_transform(Fuzzy.iloc[:, 5])\n",
        "Fuzzy.iloc[:, 6]= label_encoder.fit_transform(Fuzzy.iloc[:, 6])\n",
        "Fuzzy.iloc[:, 7]= label_encoder.fit_transform(Fuzzy.iloc[:, 7])\n",
        "Fuzzy.iloc[:, 8]= label_encoder.fit_transform(Fuzzy.iloc[:, 8])\n",
        "Fuzzy.iloc[:, 9]= label_encoder.fit_transform(Fuzzy.iloc[:, 9])\n",
        "Fuzzy.iloc[:, 10]= label_encoder.fit_transform(Fuzzy.iloc[:, 10])\n",
        "Fuzzy.iloc[:, 11]= label_encoder.fit_transform(Fuzzy.iloc[:, 11])\n",
        "Fuzzy.iloc[:, 12]= label_encoder.fit_transform(Fuzzy.iloc[:, 12])\n",
        "Fuzzy.iloc[:, 13]= label_encoder.fit_transform(Fuzzy.iloc[:, 13])\n",
        "Fuzzy.iloc[:, 14]= label_encoder.fit_transform(Fuzzy.iloc[:, 14])\n",
        "Fuzzy.iloc[:, 15]= label_encoder.fit_transform(Fuzzy.iloc[:, 15])\n",
        "#Fuzzy.iloc[:, 16]= label_encoder.fit_transform(Fuzzy.iloc[:, 16])\n",
        "\n",
        "#Class4:Impersonation\n",
        "\n",
        "Impersonation.iloc[:, 0]= label_encoder.fit_transform(Impersonation.iloc[:, 0])\n",
        "Impersonation.iloc[:, 1]= label_encoder.fit_transform(Impersonation.iloc[:, 1])\n",
        "Impersonation.iloc[:, 2]= label_encoder.fit_transform(Impersonation.iloc[:, 2])\n",
        "Impersonation.iloc[:, 3]= label_encoder.fit_transform(Impersonation.iloc[:, 3])\n",
        "Impersonation.iloc[:, 4]= label_encoder.fit_transform(Impersonation.iloc[:, 4])\n",
        "Impersonation.iloc[:, 5]= label_encoder.fit_transform(Impersonation.iloc[:, 5])\n",
        "Impersonation.iloc[:, 6]= label_encoder.fit_transform(Impersonation.iloc[:, 6])\n",
        "Impersonation.iloc[:, 7]= label_encoder.fit_transform(Impersonation.iloc[:, 7])\n",
        "Impersonation.iloc[:, 8]= label_encoder.fit_transform(Impersonation.iloc[:, 8])\n",
        "Impersonation.iloc[:, 9]= label_encoder.fit_transform(Impersonation.iloc[:, 9])\n",
        "Impersonation.iloc[:, 10]= label_encoder.fit_transform(Impersonation.iloc[:, 10])\n",
        "Impersonation.iloc[:, 11]= label_encoder.fit_transform(Impersonation.iloc[:, 11])\n",
        "Impersonation.iloc[:, 12]= label_encoder.fit_transform(Impersonation.iloc[:, 12])\n",
        "Impersonation.iloc[:, 13]= label_encoder.fit_transform(Impersonation.iloc[:, 13])\n",
        "Impersonation.iloc[:, 14]= label_encoder.fit_transform(Impersonation.iloc[:, 14])\n",
        "Impersonation.iloc[:, 15]= label_encoder.fit_transform(Impersonation.iloc[:, 15])\n",
        "#Impersonation.iloc[:, 16]= label_encoder.fit_transform(Impersonation.iloc[:, 16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCbkOA554gFL"
      },
      "outputs": [],
      "source": [
        "label1 = []\n",
        "for i in range(len(AttackFree)):\n",
        "  label1.append(1)\n",
        "\n",
        "label2 = []\n",
        "for i in range(len(DoS)):\n",
        "  label2.append(2)\n",
        "\n",
        "label3 = []\n",
        "for i in range(len(Fuzzy)):\n",
        "  label3.append(3)\n",
        "\n",
        "label4 = []\n",
        "for i in range(len(Impersonation)):\n",
        "  label4.append(4)\n",
        "\n",
        "Dataset = np.concatenate((AttackFree, DoS, Fuzzy, Impersonation))\n",
        "label = np.concatenate((label1, label2, label3, label4))\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_Train, X_Test, Y_Train, Y_Test = train_test_split(Dataset, label, test_size = 0.25, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "sc_X = StandardScaler()\n",
        "X_Train = sc_X.fit_transform(X_Train)\n",
        "X_Test = sc_X.transform(X_Test)\n",
        "# do your work here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X9ABian4kFV"
      },
      "outputs": [],
      "source": [
        "# SVM Classifier\n",
        "\n",
        "#Fitting the classifier into the Training set:SVM Training\n",
        "#kernel = precomputed, rbf,linear,polynomial, poly\n",
        "from datetime import datetime\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Defining SVM classifier\n",
        "classifier_svm = SVC(kernel='rbf', gamma='scale', random_state=0, max_iter=1000, tol=0.0001, verbose=False, class_weight=None, C=100.0)\n",
        "\n",
        "# SVM Training\n",
        "start_time_1 = datetime.now()\n",
        "classifier_svm.fit(X_Train, Y_Train)\n",
        "end_time_1 = datetime.now()\n",
        "print('Training Duration: {}'.format(end_time_1 - start_time_1))\n",
        "\n",
        "# SVM Testing\n",
        "start_time_2 = datetime.now()\n",
        "# Predicting the test set results\n",
        "Y_Pred_svm = classifier_svm.predict(X_Test)\n",
        "end_time_2 = datetime.now()\n",
        "print('Testing Duration: {}'.format(end_time_2 - start_time_2))\n",
        "\n",
        "print('Testing Duration: {}'.format(end_time_2 - start_time_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyUdM3LN4mhK"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix :SVM\n",
        "cm_svm = confusion_matrix(Y_Test, Y_Pred_svm)\n",
        "cm_svm\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "font = {'family' : 'sans-serif',\n",
        "        'size'   : 14}\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "label = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
        "\n",
        "\n",
        "df_cm_svm = pd.DataFrame(cm_svm, index = [i for i in label],\n",
        "                  columns = [i for i in label])\n",
        "\n",
        "plt.figure(figsize = (7,5))\n",
        "sn.heatmap(df_cm_svm, annot=True, fmt='.0f', cmap='Blues')\n",
        "plt.ylabel('True Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcyhtIi24pyk"
      },
      "outputs": [],
      "source": [
        "#evaluation for SVM\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_Test, Y_Pred_svm))\n",
        "print(\"Precision:\",metrics.precision_score(Y_Test, Y_Pred_svm, average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"F1_Score:\",metrics.f1_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"Cohen_Kappa_Score:\",sklearn.metrics.cohen_kappa_score(Y_Test, Y_Pred_svm, labels=None, weights=None, sample_weight=None))\n",
        "#print(\"MSE:\",metrics.mean_squared_error(Y_Test,Y_Pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbT5uEJ94sA6"
      },
      "outputs": [],
      "source": [
        "# Individual Clasification- SVM\n",
        "\n",
        "print(classification_report(Y_Test, Y_Pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mzusEv64umL"
      },
      "outputs": [],
      "source": [
        "#DT classifier\n",
        "# Fitting the classifier into the Training set:Decision Tree (DT) Training\n",
        "\n",
        "classifier_dt = tree.DecisionTreeClassifier(criterion='gini', splitter='best',random_state=0, max_depth=None)\n",
        "\n",
        "start_time_1 = datetime.now()\n",
        "\n",
        "classifier_dt.fit(X_Train, Y_Train)\n",
        "\n",
        "end_time_1 = datetime.now()\n",
        "print('Training Duration: {}'.format(end_time_1 - start_time_1))\n",
        "\n",
        "#DT Testing\n",
        "start_time_2 = datetime.now()\n",
        "# Predicting the test set results\n",
        "Y_Pred_dt = classifier_dt.predict(X_Test)\n",
        "\n",
        "end_time_2 = datetime.now()\n",
        "print('Testing Duration: {}'.format(end_time_2 - start_time_2))\n",
        "Y_Pred_dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuhoaLVS4wp4"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix :DT\n",
        "cm_dt = confusion_matrix(Y_Test, Y_Pred_dt)\n",
        "cm_dt\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "font = { 'family': 'sans-serif',\n",
        "        'weight': 'normal',\n",
        "        'size': 14 }\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "label = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
        "\n",
        "\n",
        "df_cm_dt = pd.DataFrame(cm_dt, index = [i for i in label],\n",
        "                  columns = [i for i in label])\n",
        "\n",
        "plt.figure(figsize = (7,5))\n",
        "sn.heatmap(df_cm_dt, annot=True, fmt='.0f', cmap='Blues')\n",
        "plt.ylabel('True Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMozqVTf4xaC"
      },
      "outputs": [],
      "source": [
        "#evaluation for DT\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_Test, Y_Pred_dt))\n",
        "print(\"Precision:\",metrics.precision_score(Y_Test, Y_Pred_dt, average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"F1_Score:\",metrics.f1_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"Cohen_Kappa_Score:\",sklearn.metrics.cohen_kappa_score(Y_Test, Y_Pred_dt, labels=None, weights=None, sample_weight=None))\n",
        "#print(\"MSE:\",metrics.mean_squared_error(Y_Test,Y_Pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhQ00wlQ4zqs"
      },
      "outputs": [],
      "source": [
        "# Individual Clasification- DT\n",
        "\n",
        "print(classification_report(Y_Test, Y_Pred_dt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxPSN8yA43iK"
      },
      "outputs": [],
      "source": [
        "# KNN classifier\n",
        "#Fitting the classifier into the Training set:K-nearest Neighbour Training\n",
        "#(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
        "#metric (Manhattan Distance, minkowski distance, Euclidean Distance, Cosine Distance, Jaccard Distance, Hamming Distance)\n",
        "#n_neighbors = 20\n",
        "classifier_knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "start_time_1 = datetime.now()\n",
        "\n",
        "classifier_knn.fit(X_Train, Y_Train)\n",
        "\n",
        "end_time_1 = datetime.now()\n",
        "print('Training Duration: {}'.format(end_time_1 - start_time_1))\n",
        "\n",
        "# KNN Testing\n",
        "start_time_2 = datetime.now()\n",
        "# Predicting the test set results\n",
        "Y_Pred_knn = classifier_knn.predict(X_Test)\n",
        "\n",
        "end_time_2 = datetime.now()\n",
        "print('Testing Duration: {}'.format(end_time_2 - start_time_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFaJbiOl45bq"
      },
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix :knn\n",
        "cm_knn = confusion_matrix(Y_Test, Y_Pred_knn)\n",
        "cm_knn\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "font = { 'family': 'sans-serif',\n",
        "        'weight': 'normal',\n",
        "        'size': 14 }\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "label = ['AttackFree', 'DoS', 'Fuzzy', 'Impersonation']\n",
        "\n",
        "\n",
        "df_cm_knn = pd.DataFrame(cm_knn, index = [i for i in label],\n",
        "                  columns = [i for i in label])\n",
        "\n",
        "plt.figure(figsize = (7,5))\n",
        "sn.heatmap(df_cm_knn, annot=True, fmt='.0f', cmap='Blues')\n",
        "plt.ylabel('True Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1OtVtG947AK"
      },
      "outputs": [],
      "source": [
        "#evaluation for KNN\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_Test, Y_Pred_knn))\n",
        "print(\"Precision:\",metrics.precision_score(Y_Test, Y_Pred_knn, average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"F1_Score:\",metrics.f1_score(Y_Test, Y_Test, average='micro'))\n",
        "print(\"Cohen_Kappa_Score:\",sklearn.metrics.cohen_kappa_score(Y_Test, Y_Pred_knn, labels=None, weights=None, sample_weight=None))\n",
        "#print(\"MSE:\",metrics.mean_squared_error(Y_Test,Y_Pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ifhNq949hD"
      },
      "outputs": [],
      "source": [
        "# Individual Clasification- KNN\n",
        "\n",
        "print(classification_report(Y_Test, Y_Pred_knn))"
      ]
    }
  ]
}